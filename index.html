<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="stylesheet" href="css/jemdoc.css" type="text/css" />
<link rel="stylesheet" href="css/myMiddle.css" type="text/css" />
<title>Xufeng YAO - The Chinese University of Hong Kong</title>
</head>
<body>
<div id="layout-content">
<table class="imgtable"><tr><td>
<img src="img/photo-1.jpg" alt="" width="126px" />&nbsp;</td>
<td align="left"><h1>Xufeng YAO</h1>
<p><b>Ph.D. student</b>  </p>
<p><a href="http://www.cse.cuhk.edu.hk" target=&ldquo;blank&rdquo;>Department of Computer Science and Engineering</a> <br />
<a href="http://www.cuhk.edu.hk/english/index.html" target=&ldquo;blank&rdquo;>The Chinese University of Hong Kong</a> <br />
<b>Office</b>:Rm 905, Ho Sin Hang Engineering Building <br />
<b>Email</b>:xfyao[at]cse.cuhk.edu.hk <br /></p>

<p>
    <a href="https://scholar.google.com/citations?user=1F6PeVAAAAAJ&hl=en">
        <img src="img/google-scholar.png" style="width: 30px;height: 30px;">
    </a>
    <a href="https://github.com/yaoxufeng">
        <img src="img/github.png" style="width: 30px; height: 30px;">
    </a>
</p>

</td></tr></table>
<h2>Biography</h2>
<p>I am a third-year Ph.D. student at the <a href="http://www.cse.cuhk.edu.hk" target=&ldquo;blank&rdquo;>Department of Computer Science and Engineering</a>,  
<a href="http://www.cuhk.edu.hk/english/index.html" target=&ldquo;blank&rdquo;>The Chinese University of Hong Kong (CUHK)</a>, 
under the supervision of <a href="http://www.cse.cuhk.edu.hk/~byu/" target=&ldquo;blank&rdquo;>Prof. Bei Yu</a> and <a href="https://henryhxu.github.io/index.html" target=&ldquo;blank&rdquo;>Prof. Hong Xu</a>  since Fall 2021.
Previously, I received my B.Eng. in Information System and Information Management from <a href="https://www.fudan.edu.cn" target=&ldquo;blank&rdquo;>Fudan University (FDU)</a> in 2016 and Msc in Computer Science from <a href="https://www.cuhk.edu.hk" target=&ldquo;blank&rdquo;>The Chinese University of HongKong (CUHK)</a> in 2020. My research interests include Large Language Model, Computer Vision and Machine Learning in EDA.</p>

<h2>Research Summary</h2>
<ul>
  <li>Large Language Model (MLCAD23, TCAD24, DAC24)</li>
  <li>Computer Vision & Deep Learning (ICCAD20, CVPR22, CVPR23, ICCV23, TNNLS23, ECCV24, AAAI24)</li>
  <li>Machine Learning in EDA (ICCAD21, ICCAD22, TCAD22, MLCAD23, TCAD23, DAC24)</li>
</ul>


<h2>Publications</h2>
<h3>Conference papers</h3>
<ul>

<li><p>[C1]
Zixiao Wang, Yunheng Shen, <b>Xufeng Yao</b>, Wenqian Zhao, Yang Bai, Farzan Farnia, Bei Yu,
&ldquo;ChatPattern: Layout Pattern Customization via Natural Language&rdquo;,
ACM/IEEE Design Automation Conference (<b>DAC</b>), San Francisco, Jun.&nbsp;23&ndash;27, 2024.</p>
</li>

<li><p>[C2]
<b>Xufeng Yao</b>, Fanbin Lu, Yuechen Zhang, Xinyun Zhang, Wenqian Zhao, Bei Yu,
&ldquo;<a href="https://doi.org/10.1609/aaai.v38i15.29579" target=&rdquo;blank&ldquo;>Progressively Knowledge Distillation via Re-parameterizing Diffusion Reverse Process</a>&rdquo;,
AAAI Conference on Artificial Intelligence (<b>AAAI</b>), Vancouver, Feb.&nbsp;20&ndash;27, 2024.
(<a href="./papers/C199-AAAI2024-KDiffusion.pdf" target=&ldquo;blank&rdquo;>paper</a>)
(<a href="./papers/C199-AAAI2024-KDiffusion-slides.pdf" target=&ldquo;blank&rdquo;>slides</a>)
(<a href="./papers/C199-AAAI2024-KDiffusion-poster.pdf" target=&ldquo;blank&rdquo;>poster</a>)</p>
</li>

<li><p>[C3] 
Haoyuan Wu, Xinyun Zhang, Peng Xu, Peiyu Liao, <b>Xufeng Yao</b>, Bei Yu,
&ldquo;<a href="https://doi.org/10.1609/aaai.v38i6.28415" target=&rdquo;blank&ldquo;>p-Laplacian Adaptation for Generative Pre-trained Vision-Language Models</a>&rdquo;,
AAAI Conference on Artificial Intelligence (<b>AAAI</b>), Vancouver, Feb.&nbsp;20&ndash;27, 2024.
(<a href="./papers/C198-AAAI2024-AttnAdapter.pdf" target=&ldquo;blank&rdquo;>paper</a>)
(<a href="./papers/C198-AAAI2024-AttnAdapter-slides.pdf" target=&ldquo;blank&rdquo;>slides</a>)
(<a href="./papers/C198-AAAI2024-AttnAdapter-poster.pdf" target=&ldquo;blank&rdquo;>poster</a>)
<b>(Oral)</b></p>
</li>

<li><p>[C4] Wanli Chen, <b>Xufeng Yao</b>, Xinyun Zhang, Bei Yu,
&ldquo;<a href="https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Efficient_Deep_Space_Filling_Curve_ICCV_2023_paper.html" target=&rdquo;blank&ldquo;>Efficient Deep Space Filling Curve</a>&rdquo;,
IEEE International Conference on Computer Vision (<b>ICCV</b>), Paris, Oct.&nbsp;02&ndash;06, 2023.
(<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Efficient_Deep_Space_Filling_Curve_ICCV_2023_paper.pdf" target=&ldquo;blank&rdquo;>paper</a>)
(<a href="./papers/C178-ICCV2023-DeepCurve-poster.pdf" target=&ldquo;blank&rdquo;>poster</a>)</p>
</li>

<li><p>[C5] Zhuolun He, Haoyuan Wu, Xinyun Zhang, <b>Xufeng Yao</b>, Su Zheng, Haisheng Zheng and Bei Yu,
&ldquo;<a href="https://doi.org/10.1109/MLCAD58807.2023.10299852" target=&rdquo;blank&ldquo;>ChatEDA: A Large Language Model Powered Autonomous Agent for EDA</a>&rdquo;,
ACM/IEEE Workshop on Machine Learning for CAD (<b>MLCAD</b>), Utah, Sep.&nbsp;11-13, 2023.
(<a href="./papers/C177-MLCAD2023-ChatEDA.pdf" target=&ldquo;blank&rdquo;>paper</a>)
(<a href="https://arxiv.org/abs/2308.10204" target=&ldquo;blank&rdquo;>arXiv</a>)</p>
</li>

<li><p>[C6] Wenqian Zhao, <b>Xufeng Yao</b>, Ziyang Yu, Guojin Chen, Yuzhe Ma, Bei Yu, Martin Wong,
&ldquo;<a href="https://doi.org/10.1145/3508352.3549468" target=&rdquo;blank&ldquo;>AdaOPC: A Self-Adaptive Mask Optimization Framework For Real Design Patterns</a>&rdquo;,
IEEE/ACM International Conference on Computer-Aided Design (<b>ICCAD</b>), San Diego, Oct.&nbsp;30&ndash;Nov.&nbsp;3, 2022.
(<a href="./papers/C148-ICCAD2022-AdaOPC.pdf" target=&ldquo;blank&rdquo;>paper</a>)
(<a href="./papers/C148-ICCAD2022-AdaOPC-slides.pdf" target=&ldquo;blank&rdquo;>slides</a>)
(<img src="img/logo-youtube.jpg" height=20><a href="https://youtu.be/Vj_gtNXfqFY" target=&ldquo;blank&rdquo;>video</a>)</p>
</li>

<li><p>[C7] <b>Xufeng Yao</b>, Yang Bai, Xinyun Zhang, Yuechen Zhang, Qi Sun, Ran Chen, Ruiyu Li, Bei Yu,
&ldquo;<a href="https://openaccess.thecvf.com/content/CVPR2022/html/Yao_PCL_Proxy-Based_Contrastive_Learning_for_Domain_Generalization_CVPR_2022_paper.html" target=&rdquo;blank&ldquo;>PCL: Proxy-based Contrastive Learning for Domain Generalization</a>&rdquo;,
IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), New Orleans, Jun.&nbsp;19&ndash;24, 2022.
(<a href="./papers/C144-CVPR2022-PCL.pdf" target=&ldquo;blank&rdquo;>paper</a>)
(<a href="./papers/C144-CVPR2022-PCL-poster.pdf" target=&ldquo;blank&rdquo;>poster</a>)
(<a href="./papers/C144-CVPR2022-PCL-slides.pdf" target=&ldquo;blank&rdquo;>slides</a>)
(<img src="img/logo-youtube.jpg" height=20><a href="https://youtu.be/Yj1n8hVJUes?list=PLKbKL3X7jNoHlJR8WlmANheQHG7TImAYp" target=&ldquo;blank&rdquo;>video</a>)
(<img src="img/logo-github.jpg" height=20><a href="https://github.com/yaoxufeng/PCL-Proxy-based-Contrastive-Learning-for-Domain-Generalization" target=&ldquo;blank&rdquo;>code</a>)</p>
</li>

<li><p>[C8] Xinyun Zhang, Binwu Zhu, <b>Xufeng Yao</b>, Qi Sun, Ruiyu Li, Bei Yu,
&ldquo;<a href="https://aaai-2022.virtualchair.net/poster_aaai10147" target=&rdquo;blank&ldquo;>Context-based Contrastive Learning for Scene Text Recognition</a>&rdquo;,
AAAI Conference on Artificial Intelligence (<b>AAAI</b>), Feb.&nbsp;22&ndash;Mar.&nbsp;1, 2022.
(<a href="./papers/C139-AAAI2022-ConCLR.pdf" target=&ldquo;blank&rdquo;>paper</a>)
(<a href="./papers/C139-AAAI2022-ConCLR-poster.pdf" target=&ldquo;blank&rdquo;>poster</a>)
(<img src="img/logo-youtube.jpg" height=20><a href="https://aaai-2022.virtualchair.net/poster_aaai10147" target=&ldquo;blank&rdquo;>video</a>)</p>
</li>

<li><p>[C9] Yang Bai, <b>Xufeng Yao</b>, Qi Sun, Bei Yu,
&ldquo;<a href="https://doi.org/10.1109/ICCAD51958.2021.9643487" target=&rdquo;blank&ldquo;>AutoGTCO: Graph and Tensor Co-Optimize for Image Recognition with Transformers on GPU</a>&rdquo;,
IEEE/ACM International Conference on Computer-Aided Design (<b>ICCAD</b>), Nov.&nbsp;1&ndash;4, 2021.
(<a href="./papers/C129-ICCAD2021-AutoGTCO.pdf" target=&ldquo;blank&rdquo;>paper</a>)
(<a href="./papers/C129-ICCAD2021-AutoGTCO-slides.pdf" target=&ldquo;blank&rdquo;>slides</a>)
(<img src="img/logo-youtube.jpg" height=20><a href="https://youtu.be/7Fx_hmLBihg" target=&ldquo;blank&rdquo;>video</a>)</p>
</li>

<li><p>[C10] Qi Sun, Arjun Ashok Rao, <b>Xufeng Yao</b>, Bei Yu, Shiyan Hu,
&ldquo;<a href="https://doi.org/10.1145/3400302.3415758" target=&rdquo;blank&ldquo;>Counteracting Adversarial Attack in Autonomous Driving</a>&rdquo;,
IEEE/ACM International Conference on Computer-Aided Design (<b>ICCAD</b>), Nov.&nbsp;2&ndash;5, 2020.
(<a href="papers/C105-ICCAD2020-Stereo.pdf" target=&ldquo;blank&rdquo;>paper</a>)
(<a href="papers/C105-ICCAD2020-Stereo-slides.pdf" target=&ldquo;blank&rdquo;>slides</a>)
(<a href="https://whova.com/portal/webapp/iccad_202011/Agenda/1273128" target=&ldquo;blank&rdquo;>whova</a>)</p>
</li>
</ul>

<h3>Journal papers</h3>
<ul>

<li><p>[J1] Haoyuan Wu, Zhuolun He, Xinyun Zhang, <b>Xufeng Yao</b>, Su Zheng, Haisheng Zheng, Bei Yu,
&ldquo;<a href="https://doi.org/10.1109/TCAD.2024.3383347" target=&rdquo;blank&ldquo;>ChatEDA: A Large Language Model Powered Autonomous Agent for EDA</a>&rdquo;,
accepted by IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (<b>TCAD</b>).</p>
</li>

<li><p>[J2]
Wenqian Zhao, <b>Xufeng Yao</b>, Shuo Yin, Yang Bai, Ziyang Yu, Yuzhe Ma, Bei Yu, Martin D.F.&nbsp;Wong,
&ldquo;<a href="https://doi.org/10.1109/TCAD.2024.3378600" target=&rdquo;blank&ldquo;>AdaOPC 2.0: Enhanced Adaptive Mask Optimization Framework for Via Layers</a>&rdquo;,
accepted by IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (<b>TCAD</b>).</p>
</li>

<li><p>[J3] Zehua Pei, <b>Xufeng Yao</b>, Wenqian Zhao, Bei Yu,
&ldquo;<a href="https://doi.org/10.1109/TNNLS.2023.3300309" target=&rdquo;blank&ldquo;>Quantization via Distillation and Contrastive Learning</a>&rdquo;,
accepted by IEEE Transactions on Neural Networks and Learning Systems (<b>TNNLS</b>).</p>
</li>

<li><p>[J4] Yuzhe Ma, <b>Xufeng Yao</b>, Ran Chen, Ruiyu Li, Xiaoyong Shen, Bei Yu,
&ldquo;<a href="https://doi.org/10.1109/TNNLS.2022.3194533" target=&rdquo;blank&ldquo;>Small is Beautiful: Compressing Deep Neural Networks for Partial Domain Adaptation</a>&rdquo;,
IEEE Transactions on Neural Networks and Learning Systems (<b>TNNLS</b>), vol.&nbsp;35, no.&nbsp;03, pp.&nbsp;3575&ndash;3585, 2024.
(<a href="./papers/J104-TNNLS2024-DA-Compress.pdf" target=&ldquo;blank&rdquo;>paper</a>)</p>
</li>

<li><p>[J5] 
Yang Bai, <b>Xufeng Yao</b>, Qi Sun, Wenqian Zhao, Shixin Chen, Zixiao Wang, Bei Yu,
&ldquo;<a href="https://doi.org/10.1109/TCAD.2023.3317169" target=&rdquo;blank&ldquo;>GTCO: Graph and Tensor Co-Design for Transformer-based Image Recognition on Tensor Cores</a>&rdquo;,
IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (<b>TCAD</b>), vol.&nbsp;43, no.&nbsp;02, pp.&nbsp;586&ndash;599, 2024.
(<a href="./papers/J100-TCAD2024-GTCO.pdf" target=&ldquo;blank&rdquo;>paper</a>)</p>
</li>

<li><p>[J6] Qi Sun, <b>Xufeng Yao</b>, Arjun Ashok Rao, Bei Yu, Shiyan Hu,
&ldquo;<a href="https://doi.org/10.1109/TCAD.2022.3166112" target=&rdquo;blank&ldquo;>Counteracting Adversarial Attacks in Autonomous Driving</a>&rdquo;,
IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (<b>TCAD</b>), vol.&nbsp;41, no.&nbsp;12, pp.&nbsp;5193&ndash;5206, 2022.
(<a href="./papers/J75-TCAD2022-Stereo.pdf" target=&ldquo;blank&rdquo;>paper</a>)</p>
</li>

</ul>

<h2>Experience</h2>
<h3>PingAn-OneConnect</h3>
<ul>
<li><p>AI engineer, GammaLab</p>
</li>
<li><p>2017-2019, Shanghai</p>
</li>
<li><p>Topic: Computer Vision, Knowledge Graph</p>
</li>
</ul>
<h3>SmartMore</h3>
<ul>
<li><p>Researcher, Heterogeneous Computing Group</p>
</li>
<li><p>May. 2020 &ndash; July. 2021, Hong Kong site</p>
</li>
<li><p>Topic: OCR; LayoutLM</p>
</li>
</ul>
<h3>Huawei</h3>
<ul>
<li><p>Research Intern, 2012 Laboratories</p>
</li>
<li><p>Sep. 2023 &ndash; Now, Hong Kong site</p>
</li>
<li><p>Topic: LLM4code; LLM agent</p>
</li>
</ul>

<h2>Quote</h2>
<p>Last but not least, I would like to share a famous quote that resonates with my research style and expectations, which I came across during my academic journey. </p>

</p>Nothing in the world can take the place of persistence. </p>

</p>Talent will not; nothing is more common than unsuccessful men with talent. </p>
</p>Genius will not; unrewarded genius is almost a proverb. </p>
</p>Education will not; the world is full of educated derelicts.</p>

</p><b>Persistence and determination alone are omnipotent.</b></p>


</div>
</body>
</html>
